<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="hallucinate.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Sans:wght@100..900&display=swap">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@100..900&display=swap">
  <title>(Hal)lucinator</title>
</head>
<body>

<div class="flex-container banner">
  <div class="flex-column-wide" style="text-align:left; margin-top:20px;">
    <h1 class="h1-thin">The most human AI yet.</h1>
    <h1>(HAL)lucinator</h1>
  </div>
</div>

<div class="flex-container">	

  <div class="flex-column-wide" style="margin:40px auto 30px auto;">
	<h1 class="h1-thin"><i>"To err is human"</i></h1>
  </div>

  <div class="flex-column">
    <p>Over</p><h1 class="h1-large">175 billion</h1><p>parameters</p><hr>
    <p>Over</p><h1 class="h1-large" style="margin-top:-5px;">100 terrabytes</h1><p>of text data</p><hr>
	<p>Over</p><h1 class="h1-large" style="margin-top:-5px;">$100 million</h1><p>invested in compute resources</p><hr>
    <p>Over</p><h1 class="h1-large" style="margin-top:-5px;">3,000 petaflops</h1><p>of compute power</p><hr>
    <p>Over</p><h1 class="h1-large" style="margin-top:-5px;">100 million</h1><p>active users</p>
    <div style="margin:50px auto 0 auto"><h2><span style="color:#B5C0D0;">⬤</span> → <span style="color:#CCD3CA;">⬤</span> → <span style="color:#F5E8DD;">⬤</span> → <span style="color:#EED3D9;">⬤</span></h2></div>
  </div>

  <div class="flex-column">
    <div class="box-1"><h2><b>Tokenization</b><br>Your input text is broken down into smaller units called tokens (words or subwords). This helps the model understand and process the text more efficiently.</h2></div>
    <div class="box-1"><h2><b>Preprocessing</b><br>The text is cleaned and prepared for analysis, including removing irrelevant characters and normalizing the text.</h2></div>
	<h2>↓</h2>
    <div class="box-2"><h2><b>Contextual Understanding</b><br>The model uses a transformer architecture to understand the context and meaning of your input. It considers the entire conversation history to generate relevant responses.</h2></div>
    <div class="box-2"><h2><b>Inference</b><br>The model performs statistical pattern matching and uses deep learning techniques to predict the most appropriate response based on the input and context.</h2></div>
	<h2>↓</h2>
    <div class="box-3"><h2><b>Decoding</b><br>The model generates a sequence of tokens that form the response. This involves selecting words that fit the context and flow of the conversation.</h2></div>
    <div class="box-3"><h2><b>Postprocessing</b><br>The generated response is refined to ensure it’s coherent and appropriate. This step may include formatting adjustments and error corrections.</h2></div>
	<h2>↓</h2>
    <div class="box-4"><h2><b>Rendering</b><br>The response is formatted and displayed in the chat interface, ready for you to read.</h2></div>
  </div>

  <div class="flex-column-wide" style="margin:0 auto 80px auto;">
	<h1 class="h1-thin"><i>"To forgive, divine"</i></h1>
  </div>

</div> <!--end flex-container-->

<div class="flex-container">
  <div class="flex-column-wide footer">
    <h1 class="h1-thin">Become.</h1>
    <h1 class="h1-thin">More.</h1>
    <h1 class="h1-thin">Human.</h1>
  </div>
</div>

</body>
</html>
